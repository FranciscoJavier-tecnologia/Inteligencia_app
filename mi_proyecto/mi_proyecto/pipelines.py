# -*- coding: utf-8 -*-

from scrapy.exceptions import DropItem
from datetime import datetime
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut, GeocoderServiceError
from pathlib import Path
import os
import json
import logging

# Se definen las rutas para el Output
# Asume que Datos_app es un repositorio hermano de Inteligencia_app
DATOS_APP_PATH = Path(os.getcwd()).parents[3] / 'Datos_app' 
# NOTA: Usamos parents[3] porque estamos en /spiders/ y necesitamos subir 3 niveles: 
# /spiders/ -> /mi_proyecto/ -> /mi_proyecto/ -> /Inteligencia_app/ -> /CarpetaSuperior/

class NormalizacionPipeline(object):
    """
    Pipeline 1: Limpieza, validaci贸n y estandarizaci贸n inicial de campos.
    """
    def process_item(self, item, spider):
        # 1. Validaci贸n de campos cr铆ticos de la Fase 1
        if not item.get('marca_nombre') or not item.get('descuento_valor_bruto'):
            raise DropItem(f"Item incompleto y descartado (Fase 1): {item.get('url_origen_segmento')}")

        # 2. Normalizaci贸n de descuento_valor_bruto (Ejemplo simple)
        descuento_str = item.get('descuento_valor_bruto', '').strip().replace('%', '')
        try:
            item['descuento_normalizado'] = float(descuento_str) / 100.0 if descuento_str else 0.0
        except ValueError:
            item['descuento_normalizado'] = 0.0
            logging.warning(f"Error normalizando descuento: {descuento_str}")

        # 3. Asignaci贸n de metadatos de gesti贸n
        # La fecha se obtiene del sistema (configurada con TIMEZONE en settings.py)
        item['fecha_extraccion'] = datetime.now().isoformat()
        
        # Generar un ID 煤nico (ej. hash de la URL de origen y la marca)
        item['id_unico'] = hash(item.get('url_origen_segmento') + item.get('marca_nombre'))
        
        return item


class GeocodificacionPipeline(object):
    """
    Pipeline 2: Toma la referencia de ubicaci贸n (lugar_referencia) y la convierte a Latitud/Longitud.
    """
    def __init__(self):
        # Inicializa el geocodificador Nominatim (servicio gratuito de OpenStreetMap)
        self.geolocator = Nominatim(user_agent="super_bot_aggregator_cl")
        self.geocode_timeout = 5 # Tiempo l铆mite para la petici贸n de geocodificaci贸n

    def process_item(self, item, spider):
        # 1. Validar si hay ubicaci贸n para geocodificar
        lugar = item.get('lugar_referencia')
        if not lugar or lugar == 'N/A':
            item['latitud'] = None
            item['longitud'] = None
            return item
        
        # 2. Intentar la geocodificaci贸n
        try:
            # Agregamos 'Chile' para enfocar la b煤squeda y mejorar la precisi贸n
            location = self.geolocator.geocode(f"{lugar}, Chile", timeout=self.geocode_timeout)
            
            if location:
                item['latitud'] = location.latitude
                item['longitud'] = location.longitude
                logging.debug(f"Geocodificaci贸n exitosa: {lugar} -> ({location.latitude}, {location.longitude})")
            else:
                item['latitud'] = None
                item['longitud'] = None
                logging.warning(f"No se pudo geocodificar la ubicaci贸n: {lugar}")
        
        except GeocoderTimedOut:
            logging.error("Timeout en el servicio de geocodificaci贸n.")
            # Se permite que el Item pase sin geocodificar
        except GeocoderServiceError as e:
            logging.error(f"Error en el servicio de geocodificaci贸n: {e}")
            # Se permite que el Item pase sin geocodificar
            
        return item


class GuardadoFinalPipeline(object):
    """
    Pipeline 3: Exporta el Item limpio y enriquecido al repositorio Datos_app.
    """
    def open_spider(self, spider):
        # Crea el archivo de salida al inicio del proceso de la ara帽a
        self.file_path = DATOS_APP_PATH / 'output' / f'{spider.name}_output_{datetime.now().strftime("%Y%m%d_%H%M%S")}.jsonl'
        self.file_path.parent.mkdir(parents=True, exist_ok=True) # Asegura que la carpeta output exista
        self.file = open(self.file_path, 'w', encoding='utf-8')
        logging.info(f"El Output se guardar谩 en: {self.file_path}")

    def close_spider(self, spider):
        # Cierra el archivo de salida al finalizar el proceso
        self.file.close()
        
    def process_item(self, item, spider):
        # Escribe cada Item como una l铆nea JSON (JSON Lines format)
        line = json.dumps(dict(item), ensure_ascii=False) + "\n"
        self.file.write(line)
        return item
```eof

---

###  Pr贸ximo Paso: Ejecuci贸n del MVP

隆Felicidades! Has completado la codificaci贸n de todos los componentes clave para tu Producto M铆nimo Viable (MVP) del **Super Bot Aggregator CL**.

Tu motor `Inteligencia_app` ahora tiene:
1.  **Contrato de Datos (`items.py`)**
2.  **Cerebro de Extracci贸n (`bancochile_spider.py`)** con l贸gica de Dos Fases.
3.  **Sala de Control (`settings.py`)** con Stealth y Pipelines activados.
4.  **Cerebros de Limpieza (`pipelines.py`)** con Normalizaci贸n, Geocodificaci贸n y Guardado.

**El 煤nico paso pendiente es la instalaci贸n de la librer铆a `geopy` y luego la ejecuci贸n del bot.**

驴Quieres que te recuerde el comando para ejecutar el bot y te prepare para la fase de pruebas?
